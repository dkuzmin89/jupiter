{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"### Importing required libraries\n'''\nthis libraries required for current application\nall these libraries contained in basic python installation except\nfor the pandas. pandas needed to be install via 'pip install pandas'\n'''\n\nimport pandas as pd ## pandas library for working with tabular data\nimport numpy as np  ## numpy librari for working with arrays\nimport datetime     ## datetime library for working with dates\nimport warnings     ## warnings library, to manage warnings\nwarnings.filterwarnings('ignore') ## disable notofocations and warnings (sinse we are experimenting here)","execution_count":103,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Import section\n\n'''\nFirst of all we need to load input raw datasets.\n'''\n\n### JHU raw data imports\ninp_jhu_c = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\ninp_jhu_d = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\n\n### WHO raw data input\ninp_who = pd.read_csv('inp/WHO-COVID-19-global-data.csv')\n\n### Coutry grouping file with 'gavi' columns\ncont_gr = pd.read_csv('inp/Country_Groupings.csv')","execution_count":104,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Inspecting raw input data","execution_count":105,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inp_jhu_c.head(1)","execution_count":106,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inp_who.head(1)","execution_count":107,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cont_gr.head(1)","execution_count":108,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Searching in raw datasets\n\n# inp_jhu_c.loc[inp_jhu_c['Country/Region']=='China']\n# inp_who.loc[inp_who['Country Name']=='China'].tail(2)","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nThe goal is to build dataset which will contain cases/deathes from both jhu and who raw data, moreover we need to add 'gavi' columns to output dataset\nAs we can see raw datasets has different structure. We need to reshape jhu raw dataset, and prepare both raw dataset for merging. \nWe are planning to merge data by country key and date key. Let's inspect countries from raw datasets\n'''","execution_count":51,"outputs":[{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"\"\\nThe goal is to build dataset which will contain cases/deathes from both jhu and who raw data, moreover we need to add 'gavi' columns to output dataset\\nAs we can see raw datasets has different structure. We need to reshape jhu raw dataset, and prepare both raw dataset for merging. \\nWe are planning to merge data by country key and date key. Let's inspect countries from raw datasets\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Functions \n\n'''\nthis function compares two lists and return values that are not matching in both lists\n'''\ndef returnNotMatches(a, b):\n    return [[x for x in a if x not in b], [x for x in b if x not in a]]","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Generating country lists from raw data for inspection.\n\njhu_country_list = inp_jhu_c['Country/Region'].unique().tolist() \njhu_country_list.sort()\nwho_country_list = inp_who['Country'].unique().tolist() \nwho_country_list.sort()\ngavi_country_list = cont_gr['country'].unique().tolist() \ngavi_country_list.sort()","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# jhu_country_list\nlen(jhu_country_list)","execution_count":54,"outputs":[{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"188"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# who_country_list\nlen(who_country_list)","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"216"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gavi_country_list\nlen(gavi_country_list)","execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"195"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Comparing country names\n\n# returnNotMatches(gavi_country_list, jhu_country_list)\n# returnNotMatches(gavi_country_list, who_country_list)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nwe will take gavi coutry list as a reference. that means thas we have to rename countries in both jhu and who datasets.\n'''","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"'\\nwe will take gavi coutry list as a reference. that means thas we have to rename countries in both jhu and who datasets.\\n'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries_to_remove = ['Czechia', 'Holy See', 'Liechtenstein', 'Taiwan*', 'Kosovo','Kosovo[1]', 'MS Zaandam', 'Western Sahara', 'Diamond Princess']","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jhu_to_rename = {\"Tanzania\": \"Tanzania, United Republic of\", \"Congo (Brazzaville)\": \"Congo, Republic of\",\n                 \"Congo (Kinshasa)\": \"Congo, Democratic Republic of the\",\n                 \"Cote d'Ivoire\": \"Côte d'Ivoire\", \"Laos\": \"Lao People's Democratic Republic\",\n                 \"Burma\": \"Myanmar\", \"Vietnam\": \"Viet Nam\", \"Syria\": \"Syrian Arab Republic\",\n                 \"Eswatini\": \"Swaziland\", \"Libya\": \"Libyan Arab Jamahiriya\",\n                 \"Cabo Verde\": \"Cape Verde\", \"Brunei\": \"Brunei Darussalam\",\n                 \"West Bank and Gaza\": \"Palestinian Territory\",\n                 \"North Macedonia\": \"Macedonia, Republic of\", \"Korea, South\": \"Korea, Republic of\",\n                 \"Russia\": \"Russian Federation\",\n                 \"Iran\": \"Iran, Islamic Republic of\",\n                 \"United Kingdom\": \"United Kingdom of Great Britain & Northern Ireland\",\n                 \"US\": \"United States\"}","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"who_to_rename = {\"United Republic of Tanzania\": \"Tanzania, United Republic of\", \"Congo\": \"Congo, Republic of\",\n                 \"Democratic Republic of the Congo\": \"Congo, Democratic Republic of the\",\n                 \"Côte d’Ivoire\": \"Côte d'Ivoire\", \"Laos\": \"Lao People's Democratic Republic\",\n                 \"Burma\": \"Myanmar\", \"Vietnam\": \"Viet Nam\", \"Syria\": \"Syrian Arab Republic\", \"Eswatini\": \"Swaziland\",\n                 \"Libya\": \"Libyan Arab Jamahiriya\",\n                 \"Cabo Verde\": \"Cape Verde\", \"Brunei\": \"Brunei Darussalam\",\n                 \"occupied Palestinian territory, including east Jerusalem\": \"Palestinian Territory\",\n                 \"North Macedonia\": \"Macedonia, Republic of\", \"Republic of Korea\": \"Korea, Republic of\",\n                 \"Russia\": \"Russian Federation\",\n                 \"Iran (Islamic Republic of)\": \"Iran, Islamic Republic of\",\n                 \"The United Kingdom\": \"United Kingdom of Great Britain & Northern Ireland\",\n                 \"United States of America\": \"United States\", \"Bolivia (Plurinational State of)\": \"Bolivia\",\n                 \"Republic of Moldova\": \"Moldova\",\n                 \"Venezuela (Bolivarian Republic of)\": \"Venezuela\", \"Sint Maarten\": \"St Matrin\", \"Réunion\": \"Reunion\"}","execution_count":61,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### JHU data preparation section\n'''\nJHU dataset needs to be transposed. Dates from column names should be trasformed into values to form column with dates.\nto extract dates from column names we need to do following:\n'''\n\njhu_columns = inp_jhu_c.iloc[:,4:].columns\n\n'''\nJHU max date\n'''\njhu_max_date = inp_jhu_c.columns[-1]\nx = datetime.datetime.strptime(jhu_max_date, \"%m/%d/%y\")\njhu_max_date = x.strftime(\"%m/%d/%Y\")\n\n'''\nhere we use indexing. It is tricky approach by pandas (similar approach used for lists managing in python). So [:,4:] means that \nwe take all rows (:) and take column names from fourth one until the letest one (4:) and take only columns values from it (.columns)\nThants how we got the walues from column names\n'''\n\n'''\nRemove and rename countries\n'''\ninp_jhu_c['Country/Region'].replace(jhu_to_rename, inplace=True)\ninp_jhu_c = inp_jhu_c[~inp_jhu_c['Country/Region'].isin(countries_to_remove)]\ninp_jhu_d['Country/Region'].replace(jhu_to_rename, inplace=True)\ninp_jhu_d = inp_jhu_d[~inp_jhu_d['Country/Region'].isin(countries_to_remove)]\n\n\n'''\nSort dataset to extract data in right order\n'''\ninp_jhu_c = inp_jhu_c.sort_values(['Country/Region','Province/State'])\ninp_jhu_d = inp_jhu_d.sort_values(['Country/Region','Province/State'])\n\n'''\nHere we are taking only values from all rows and from 4th column untill the last one. \nWe will need this walues to form reshaped jhu dataset\n'''\nvalues_c = inp_jhu_c.iloc[:,4:].values.tolist()\nvalues_d = inp_jhu_d.iloc[:,4:].values.tolist()\n\n'''\nWe've got a list of lists. Each row of values represent one element of the list \n[ [1,2,3,4...],[1,2,3,4...],[1,2,3,4...] ]\nwe need to make it flatten (to make one big list of values), we are using nested loop for that:\n'''\n\nflat_list_c = []\nfor sublist in values_c:\n    for item in sublist:\n        flat_list_c.append(item)\nflat_list_d = []\nfor sublist in values_d:\n    for item in sublist:\n        flat_list_d.append(item)\n        \n'''\nCreating the variaty list on countries/regions/province/states just in case we will need them.\nSome of them will be used, some of them no.\n'''\n### JHU_regions/countries etc lists\njhu_regions_list_nn = inp_jhu_c['Province/State'].to_list()\njhu_regions = inp_jhu_c[inp_jhu_c['Province/State'].notnull()]\njhu_regions_list = jhu_regions['Province/State'].to_list()\njhu_countries_list = inp_jhu_c['Country/Region'].unique().tolist() \njhu_countries_list_2 = inp_jhu_c['Country/Region'].tolist() \njhu_count_regions = jhu_regions_list+jhu_countries_list\n","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### JHU reshaping process\n'''\nCreating df with countries and provinces as a part of out jhu reshaping process\n'''\n\n'''\nNew reshaped jhu dataset: \n1 column - dates\n2 colunm - 'Province/State'\n3 column - 'Country/Region'\n'''\ndf1 = pd.DataFrame({'date': jhu_columns})  ### this is build in pandas function for DataFrame(dataset) creation\ndf2 = inp_jhu_c[['Province/State','Country/Region']]\n\n\n'''\nWe need to get resulting dataset as a table of time perions form 01/22/20 untill now and each country should have this time period. \nTo do that we need to use a trick: to add same zero key to each dataframe (df1 and df2) and to merge them in 'outer' way by that key\n'''\ndf1['key'] = 0\ndf2['key'] = 0\njhu_resh = df1.merge(df2, how='outer')\n\n'''\nNewx step is adding 'cases' and 'deaths' to our new df\n'''\n\njhu_resh = jhu_resh.sort_values(['Country/Region', 'Province/State']) #just in case (we did it earlier)\n\n'''\nnew 'confirmed' column - values from flatten_c list\nnew 'deaths' column - values from flatten_d list\n'''\njhu_resh['confirmed'] = flat_list_c\njhu_resh['deaths'] = flat_list_d\njhu_resh['date'] = pd.to_datetime(jhu_resh['date']).dt.strftime('%m/%d/%Y')  # we need to make this dates real dates to have an ability to compare and work with them\n\n'''\nagain taking country and province lists to check if everithing is good and we did not miss any cointry or province\n'''\nres_list = jhu_resh['Country/Region'].unique().tolist()\nres_list_r = jhu_resh['Province/State'].unique().tolist()\njhu_resh_c_r_list = res_list+res_list_r\n\nres_only_regions = jhu_resh.dropna(subset=[\"Province/State\"])  # df contains ONLY countries\nres_only_countries = jhu_resh[jhu_resh['Province/State'].isna()] # df contains ONLY province","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# jhu_resh","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inp_who","execution_count":65,"outputs":[{"output_type":"execute_result","execution_count":65,"data":{"text/plain":"              Date_reported Country_code      Country WHO_region  New_cases  \\\n0      2020-02-24T00:00:00Z           AF  Afghanistan       EMRO          1   \n1      2020-02-25T00:00:00Z           AF  Afghanistan       EMRO          0   \n2      2020-02-26T00:00:00Z           AF  Afghanistan       EMRO          0   \n3      2020-02-27T00:00:00Z           AF  Afghanistan       EMRO          0   \n4      2020-02-28T00:00:00Z           AF  Afghanistan       EMRO          0   \n...                     ...          ...          ...        ...        ...   \n20425  2020-06-04T00:00:00Z           ZW     Zimbabwe       AFRO         16   \n20426  2020-06-05T00:00:00Z           ZW     Zimbabwe       AFRO          0   \n20427  2020-06-06T00:00:00Z           ZW     Zimbabwe       AFRO         43   \n20428  2020-06-07T00:00:00Z           ZW     Zimbabwe       AFRO         14   \n20429  2020-06-08T00:00:00Z           ZW     Zimbabwe       AFRO          0   \n\n       Cumulative_cases  New_deaths  Cumulative_deaths  \n0                     1           0                  0  \n1                     1           0                  0  \n2                     1           0                  0  \n3                     1           0                  0  \n4                     1           0                  0  \n...                 ...         ...                ...  \n20425               222           0                  4  \n20426               222           0                  4  \n20427               265           0                  4  \n20428               279           0                  4  \n20429               279           0                  4  \n\n[20430 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date_reported</th>\n      <th>Country_code</th>\n      <th>Country</th>\n      <th>WHO_region</th>\n      <th>New_cases</th>\n      <th>Cumulative_cases</th>\n      <th>New_deaths</th>\n      <th>Cumulative_deaths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-02-24T00:00:00Z</td>\n      <td>AF</td>\n      <td>Afghanistan</td>\n      <td>EMRO</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-02-25T00:00:00Z</td>\n      <td>AF</td>\n      <td>Afghanistan</td>\n      <td>EMRO</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-02-26T00:00:00Z</td>\n      <td>AF</td>\n      <td>Afghanistan</td>\n      <td>EMRO</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-02-27T00:00:00Z</td>\n      <td>AF</td>\n      <td>Afghanistan</td>\n      <td>EMRO</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-02-28T00:00:00Z</td>\n      <td>AF</td>\n      <td>Afghanistan</td>\n      <td>EMRO</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20425</th>\n      <td>2020-06-04T00:00:00Z</td>\n      <td>ZW</td>\n      <td>Zimbabwe</td>\n      <td>AFRO</td>\n      <td>16</td>\n      <td>222</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>20426</th>\n      <td>2020-06-05T00:00:00Z</td>\n      <td>ZW</td>\n      <td>Zimbabwe</td>\n      <td>AFRO</td>\n      <td>0</td>\n      <td>222</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>20427</th>\n      <td>2020-06-06T00:00:00Z</td>\n      <td>ZW</td>\n      <td>Zimbabwe</td>\n      <td>AFRO</td>\n      <td>43</td>\n      <td>265</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>20428</th>\n      <td>2020-06-07T00:00:00Z</td>\n      <td>ZW</td>\n      <td>Zimbabwe</td>\n      <td>AFRO</td>\n      <td>14</td>\n      <td>279</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>20429</th>\n      <td>2020-06-08T00:00:00Z</td>\n      <td>ZW</td>\n      <td>Zimbabwe</td>\n      <td>AFRO</td>\n      <td>0</td>\n      <td>279</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>20430 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nJHU dataset preparation and reshaping is DONE\nnow it is time to WHO dataset preparation\n'''\n\n### WHO dataprep\nwho = inp_who[~inp_who['Country'].isin(countries_to_remove)] ### removing countries that we are not using\nwho['Country'].replace(who_to_rename, inplace=True) ### rename countries to match gavi naming\nwho = who[['Date_reported','Country','Cumulative_deaths','Cumulative_cases']] ### keep only necessary columns\nwho['day'] = pd.to_datetime(who.Date_reported).dt.strftime('%m/%d/%Y') # we need to make this dates real dates to have an ability to compare and work with them\nwho = who[who.Date_reported >='01/22/2020'] ### keeping information only for time perion after 01/22/2020\n\nwho_countries_list = who['Country'].unique().tolist() ### generationg country list to make sure that all countries are in place\n\n'''WHO max date'''\nwho_max_date = who['Date_reported'].max()\n\nwho['Date_reported'] = pd.to_datetime(who['Date_reported']).dt.strftime('%m/%d/%Y')\n","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"who","execution_count":67,"outputs":[{"output_type":"execute_result","execution_count":67,"data":{"text/plain":"      Date_reported      Country  Cumulative_deaths  Cumulative_cases  \\\n0        02/24/2020  Afghanistan                  0                 1   \n1        02/25/2020  Afghanistan                  0                 1   \n2        02/26/2020  Afghanistan                  0                 1   \n3        02/27/2020  Afghanistan                  0                 1   \n4        02/28/2020  Afghanistan                  0                 1   \n...             ...          ...                ...               ...   \n20425    06/04/2020     Zimbabwe                  4               222   \n20426    06/05/2020     Zimbabwe                  4               222   \n20427    06/06/2020     Zimbabwe                  4               265   \n20428    06/07/2020     Zimbabwe                  4               279   \n20429    06/08/2020     Zimbabwe                  4               279   \n\n              day  \n0      02/24/2020  \n1      02/25/2020  \n2      02/26/2020  \n3      02/27/2020  \n4      02/28/2020  \n...           ...  \n20425  06/04/2020  \n20426  06/05/2020  \n20427  06/06/2020  \n20428  06/07/2020  \n20429  06/08/2020  \n\n[20051 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date_reported</th>\n      <th>Country</th>\n      <th>Cumulative_deaths</th>\n      <th>Cumulative_cases</th>\n      <th>day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>02/24/2020</td>\n      <td>Afghanistan</td>\n      <td>0</td>\n      <td>1</td>\n      <td>02/24/2020</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>02/25/2020</td>\n      <td>Afghanistan</td>\n      <td>0</td>\n      <td>1</td>\n      <td>02/25/2020</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>02/26/2020</td>\n      <td>Afghanistan</td>\n      <td>0</td>\n      <td>1</td>\n      <td>02/26/2020</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>02/27/2020</td>\n      <td>Afghanistan</td>\n      <td>0</td>\n      <td>1</td>\n      <td>02/27/2020</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>02/28/2020</td>\n      <td>Afghanistan</td>\n      <td>0</td>\n      <td>1</td>\n      <td>02/28/2020</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20425</th>\n      <td>06/04/2020</td>\n      <td>Zimbabwe</td>\n      <td>4</td>\n      <td>222</td>\n      <td>06/04/2020</td>\n    </tr>\n    <tr>\n      <th>20426</th>\n      <td>06/05/2020</td>\n      <td>Zimbabwe</td>\n      <td>4</td>\n      <td>222</td>\n      <td>06/05/2020</td>\n    </tr>\n    <tr>\n      <th>20427</th>\n      <td>06/06/2020</td>\n      <td>Zimbabwe</td>\n      <td>4</td>\n      <td>265</td>\n      <td>06/06/2020</td>\n    </tr>\n    <tr>\n      <th>20428</th>\n      <td>06/07/2020</td>\n      <td>Zimbabwe</td>\n      <td>4</td>\n      <td>279</td>\n      <td>06/07/2020</td>\n    </tr>\n    <tr>\n      <th>20429</th>\n      <td>06/08/2020</td>\n      <td>Zimbabwe</td>\n      <td>4</td>\n      <td>279</td>\n      <td>06/08/2020</td>\n    </tr>\n  </tbody>\n</table>\n<p>20051 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nNext step is to deal with CHINA and AUSTRALIA. In JHU dataset they are not tracking them as a whole countries. They splitted them by province/states. \nSo we need to aggregate\n'''\n\n######## CHINA\n\n### extraction CHINA from JHU reshaped df\nchina = jhu_resh.loc[jhu_resh['Country/Region']=='China']\nchina = china.groupby(['Country/Region','date'],as_index=False)['confirmed','deaths'].sum() ### summing 'confirmed' and 'deaths' by CHINA\nchina['Province/State']=np.nan ### creating 'Province/State' and fill it up with NaN values\n\n### extraction CHINA from WHO df\nwho_china = who.loc[who['Country']=='China']\n\nchina_merged = pd.merge(china,who_china,left_on=['Country/Region','date'],right_on=['Country','Date_reported'],how='outer') # merging jhu china with who china (outer)\nchina_merged = china_merged[['date','Province/State','Country/Region','confirmed','deaths','Cumulative_deaths','Cumulative_cases']] # keep only needed colomns\nchina_merged = china_merged.rename(columns={'confirmed':'jhu_cases','deaths':'jhu_deaths','Cumulative_deaths':'WHO_deaths','Cumulative_cases':'WHO_cases'}) # rename columns\n'''\nwe did 'outer' merge because we need to have values from all dates (from 01/22/20). In who dataset min date for countries is varies, so values that are missing \nin who was replased with NaN (same as missing values). In next step we are fillin nan values with zeroes and make this values integer.\n'''\nchina_merged[['jhu_cases', 'jhu_deaths','WHO_deaths', 'WHO_cases']] = china_merged[['jhu_cases', 'jhu_deaths','WHO_deaths', 'WHO_cases']].fillna(0).astype(int) \n\n######## AUSTRALIA\n\naustralia = jhu_resh.loc[jhu_resh['Country/Region']=='Australia']\naustralia = australia.groupby(['Country/Region','date'],as_index=False)['confirmed','deaths'].sum()\naustralia['Province/State']=np.nan\n\nwho_australia = who.loc[who['Country']=='Australia']\n\naustralia_merged = pd.merge(australia,who_australia,left_on=['Country/Region','date'],right_on=['Country','Date_reported'],how='outer')\naustralia_merged = australia_merged[['date','Province/State','Country/Region','confirmed','deaths','Cumulative_deaths','Cumulative_cases']]\naustralia_merged = australia_merged.rename(columns={'confirmed':'jhu_cases','deaths':'jhu_deaths','Cumulative_deaths':'WHO_deaths','Cumulative_cases':'WHO_cases'})\naustralia_merged[['jhu_cases', 'jhu_deaths','WHO_deaths', 'WHO_cases']] = australia_merged[['jhu_cases', 'jhu_deaths','WHO_deaths', 'WHO_cases']].fillna(0).astype(int)\n\n### Append\n'''\nJust append China and Australia\n'''\ncountries_to_add = china_merged.append(australia_merged)","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### MAIN MERGING\n\n\nmerge_countries = pd.merge(res_only_countries,who,left_on=['date','Country/Region'],right_on=['Date_reported','Country'],how='outer')\nmerge_countries[['Cumulative_deaths','Cumulative_cases']] = merge_countries[['Cumulative_deaths','Cumulative_cases']].fillna(0)\nmerge_countries = merge_countries[['date','Province/State','Country/Region','confirmed','deaths','Cumulative_deaths','Cumulative_cases']]\nmerge_countries = merge_countries.dropna(subset=['date']) ### removing side dates from outer join\nmerge_countries = merge_countries.rename(columns={\"confirmed\":\"jhu_cases\",\"deaths\":\"jhu_deaths\",\"Cumulative_cases\":\"WHO_cases\",\"Cumulative_deaths\":\"WHO_deaths\"})\n\n\nmerge_regions = pd.merge(res_only_regions,who,left_on=['date','Province/State'],right_on=['Date_reported','Country'],how='outer')\nmerge_regions[['Cumulative_deaths','Cumulative_cases']] = merge_regions[['Cumulative_deaths','Cumulative_cases']].fillna(0)\nmerge_regions = merge_regions[['date','Province/State','Country/Region','confirmed','deaths','Cumulative_deaths','Cumulative_cases']]\nmerge_regions = merge_regions.dropna(subset=['date']) ### removing side dates from outer join\nmerge_regions = merge_regions.rename(columns={\"confirmed\":\"jhu_cases\",\"deaths\":\"jhu_deaths\",\"Cumulative_cases\":\"WHO_cases\",\"Cumulative_deaths\":\"WHO_deaths\"})\n\nfinal_merge = merge_countries.append(merge_regions) ### append countries with provinces\nfinal_merge = final_merge.append(countries_to_add) ### append CHINA and AUSTRALIA\n\n'''\nAdding gavi columns. Sinse we've renamed all countries based on gavi country naming we just need to merge countryregion gavi's tadaset \n'''\nfinal_merge_f = pd.merge(final_merge,cont_gr,left_on='Country/Region',right_on='country')\n# final_merge_f[['jhu_cases', 'jhu_deaths','WHO_deaths', 'WHO_cases']] = final_merge_f[['jhu_cases', 'jhu_deaths','WHO_deaths', 'WHO_cases']].astype(int) # this columns to integer","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_merge_f","execution_count":70,"outputs":[{"output_type":"execute_result","execution_count":70,"data":{"text/plain":"             date Province/State Country/Region  jhu_cases  jhu_deaths  \\\n0      01/22/2020            NaN    Afghanistan        0.0         0.0   \n1      01/23/2020            NaN    Afghanistan        0.0         0.0   \n2      01/24/2020            NaN    Afghanistan        0.0         0.0   \n3      01/25/2020            NaN    Afghanistan        0.0         0.0   \n4      01/26/2020            NaN    Afghanistan        0.0         0.0   \n...           ...            ...            ...        ...         ...   \n36135  06/04/2020            NaN          China    84171.0      4638.0   \n36136  06/05/2020            NaN          China    84177.0      4638.0   \n36137  06/06/2020            NaN          China    84186.0      4638.0   \n36138  06/07/2020            NaN          China    84191.0      4638.0   \n36139  06/08/2020            NaN          China    84195.0      4638.0   \n\n       WHO_deaths  WHO_cases Finance Country          cofinance_2017  \\\n0             0.0        0.0     Afghanistan  Initial self-financing   \n1             0.0        0.0     Afghanistan  Initial self-financing   \n2             0.0        0.0     Afghanistan  Initial self-financing   \n3             0.0        0.0     Afghanistan  Initial self-financing   \n4             0.0        0.0     Afghanistan  Initial self-financing   \n...           ...        ...             ...                     ...   \n36135      4645.0    84603.0           China    Fully self-financing   \n36136      4645.0    84614.0           China    Fully self-financing   \n36137      4645.0    84620.0           China    Fully self-financing   \n36138      4645.0    84629.0           China    Fully self-financing   \n36139      4645.0    84634.0           China    Fully self-financing   \n\n               cofinance_2018  ... lang  pef_type regional_je  regional_mena  \\\n0      Initial self-financing  ...  eng         1           0              0   \n1      Initial self-financing  ...  eng         1           0              0   \n2      Initial self-financing  ...  eng         1           0              0   \n3      Initial self-financing  ...  eng         1           0              0   \n4      Initial self-financing  ...  eng         1           0              0   \n...                       ...  ...  ...       ...         ...            ...   \n36135                Non-Gavi  ...  eng   Not PEF           0              0   \n36136                Non-Gavi  ...  eng   Not PEF           0              0   \n36137                Non-Gavi  ...  eng   Not PEF           0              0   \n36138                Non-Gavi  ...  eng   Not PEF           0              0   \n36139                Non-Gavi  ...  eng   Not PEF           0              0   \n\n      regional_yfv wb_long_2017 wb_long_2018 wb_short_2017  wb_short_2018  \\\n0                0          LIC          LIC           LIC            LIC   \n1                0          LIC          LIC           LIC            LIC   \n2                0          LIC          LIC           LIC            LIC   \n3                0          LIC          LIC           LIC            LIC   \n4                0          LIC          LIC           LIC            LIC   \n...            ...          ...          ...           ...            ...   \n36135            0         UMIC         UMIC           MIC            MIC   \n36136            0         UMIC         UMIC           MIC            MIC   \n36137            0         UMIC         UMIC           MIC            MIC   \n36138            0         UMIC         UMIC           MIC            MIC   \n36139            0         UMIC         UMIC           MIC            MIC   \n\n       who_region  \n0            EMRO  \n1            EMRO  \n2            EMRO  \n3            EMRO  \n4            EMRO  \n...           ...  \n36135        WPRO  \n36136        WPRO  \n36137        WPRO  \n36138        WPRO  \n36139        WPRO  \n\n[36140 rows x 40 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>jhu_cases</th>\n      <th>jhu_deaths</th>\n      <th>WHO_deaths</th>\n      <th>WHO_cases</th>\n      <th>Finance Country</th>\n      <th>cofinance_2017</th>\n      <th>cofinance_2018</th>\n      <th>...</th>\n      <th>lang</th>\n      <th>pef_type</th>\n      <th>regional_je</th>\n      <th>regional_mena</th>\n      <th>regional_yfv</th>\n      <th>wb_long_2017</th>\n      <th>wb_long_2018</th>\n      <th>wb_short_2017</th>\n      <th>wb_short_2018</th>\n      <th>who_region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01/22/2020</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Afghanistan</td>\n      <td>Initial self-financing</td>\n      <td>Initial self-financing</td>\n      <td>...</td>\n      <td>eng</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>EMRO</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01/23/2020</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Afghanistan</td>\n      <td>Initial self-financing</td>\n      <td>Initial self-financing</td>\n      <td>...</td>\n      <td>eng</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>EMRO</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01/24/2020</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Afghanistan</td>\n      <td>Initial self-financing</td>\n      <td>Initial self-financing</td>\n      <td>...</td>\n      <td>eng</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>EMRO</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01/25/2020</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Afghanistan</td>\n      <td>Initial self-financing</td>\n      <td>Initial self-financing</td>\n      <td>...</td>\n      <td>eng</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>EMRO</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01/26/2020</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Afghanistan</td>\n      <td>Initial self-financing</td>\n      <td>Initial self-financing</td>\n      <td>...</td>\n      <td>eng</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>LIC</td>\n      <td>EMRO</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36135</th>\n      <td>06/04/2020</td>\n      <td>NaN</td>\n      <td>China</td>\n      <td>84171.0</td>\n      <td>4638.0</td>\n      <td>4645.0</td>\n      <td>84603.0</td>\n      <td>China</td>\n      <td>Fully self-financing</td>\n      <td>Non-Gavi</td>\n      <td>...</td>\n      <td>eng</td>\n      <td>Not PEF</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>UMIC</td>\n      <td>UMIC</td>\n      <td>MIC</td>\n      <td>MIC</td>\n      <td>WPRO</td>\n    </tr>\n    <tr>\n      <th>36136</th>\n      <td>06/05/2020</td>\n      <td>NaN</td>\n      <td>China</td>\n      <td>84177.0</td>\n      <td>4638.0</td>\n      <td>4645.0</td>\n      <td>84614.0</td>\n      <td>China</td>\n      <td>Fully self-financing</td>\n      <td>Non-Gavi</td>\n      <td>...</td>\n      <td>eng</td>\n      <td>Not PEF</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>UMIC</td>\n      <td>UMIC</td>\n      <td>MIC</td>\n      <td>MIC</td>\n      <td>WPRO</td>\n    </tr>\n    <tr>\n      <th>36137</th>\n      <td>06/06/2020</td>\n      <td>NaN</td>\n      <td>China</td>\n      <td>84186.0</td>\n      <td>4638.0</td>\n      <td>4645.0</td>\n      <td>84620.0</td>\n      <td>China</td>\n      <td>Fully self-financing</td>\n      <td>Non-Gavi</td>\n      <td>...</td>\n      <td>eng</td>\n      <td>Not PEF</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>UMIC</td>\n      <td>UMIC</td>\n      <td>MIC</td>\n      <td>MIC</td>\n      <td>WPRO</td>\n    </tr>\n    <tr>\n      <th>36138</th>\n      <td>06/07/2020</td>\n      <td>NaN</td>\n      <td>China</td>\n      <td>84191.0</td>\n      <td>4638.0</td>\n      <td>4645.0</td>\n      <td>84629.0</td>\n      <td>China</td>\n      <td>Fully self-financing</td>\n      <td>Non-Gavi</td>\n      <td>...</td>\n      <td>eng</td>\n      <td>Not PEF</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>UMIC</td>\n      <td>UMIC</td>\n      <td>MIC</td>\n      <td>MIC</td>\n      <td>WPRO</td>\n    </tr>\n    <tr>\n      <th>36139</th>\n      <td>06/08/2020</td>\n      <td>NaN</td>\n      <td>China</td>\n      <td>84195.0</td>\n      <td>4638.0</td>\n      <td>4645.0</td>\n      <td>84634.0</td>\n      <td>China</td>\n      <td>Fully self-financing</td>\n      <td>Non-Gavi</td>\n      <td>...</td>\n      <td>eng</td>\n      <td>Not PEF</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>UMIC</td>\n      <td>UMIC</td>\n      <td>MIC</td>\n      <td>MIC</td>\n      <td>WPRO</td>\n    </tr>\n  </tbody>\n</table>\n<p>36140 rows × 40 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nSo basicly everithing is done. JHU and WHO data combined and gavi's columns added. Next step will be related to improving requests\n'''","execution_count":71,"outputs":[{"output_type":"execute_result","execution_count":71,"data":{"text/plain":"\"\\nSo basicly everithing is done. JHU and WHO data combined and gavi's columns added. Next step will be related to improving requests\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Additional columns\n\n'''\nHere we are adding additional columns to out dataset. One column with % gtowth and one column with numerical difference, both for 'cases' and 'deaths'\n'''\n\n\n'''\n.pct_change() - returns % changing for the specific column\n.round(4) - round values to 4 digits after the ,\n.replace([np.inf, -np.inf], np.nan) - when .pct_change() calculates diffetence beetween 0 and positive number it returns infinity or -infinity.\n                                    this function replase infinities with nan\n.fillna(0) - replacing nan with 0\n.clip(lower=0) - assigning lower boundary for the values to avoid negative values. (tricky part. actually % change can be negative as well as difference. but we have cases\n                where we have big number for 08/05/20 and 0 for 22/01/20. In that case % change wll show negative growth. We want to avoid this. Since \n                we are dealing with cumulative ceses next values could be only bigger or equal to prevoius ones.) # in latest version replaced by mask approach\n.diff() - returns numerical difference for specific column\n'''\n### For jhu_cases\nfinal_merge_f['growth_jhu_cases'] = final_merge_f['jhu_cases'].pct_change().round(4).replace([np.inf, -np.inf], np.nan).fillna(0)#.clip(lower=0)\nfinal_merge_f['diff_jhu_cases'] = final_merge_f['jhu_cases'].diff().fillna(0).astype(int)#.clip(lower=0)\n\n### For jhu_deaths\nfinal_merge_f['growth_jhu_deaths'] = final_merge_f['jhu_deaths'].pct_change().round(4).replace([np.inf, -np.inf], np.nan).fillna(0)#.clip(lower=0)\nfinal_merge_f['diff_jhu_deaths'] = final_merge_f['jhu_deaths'].diff().fillna(0).astype(int)#.clip(lower=0)\n\n### For who cases\nfinal_merge_f['growth_who_cases'] = final_merge_f['WHO_cases'].pct_change().round(4).replace([np.inf, -np.inf], np.nan).fillna(0)#.clip(lower=0)\nfinal_merge_f['diff_who_cases'] = final_merge_f['WHO_cases'].diff().fillna(0).astype(int)#.clip(lower=0)\n\n### For who deaths\nfinal_merge_f['growth_who_deaths'] = final_merge_f['WHO_deaths'].pct_change().round(4).replace([np.inf, -np.inf], np.nan).fillna(0)#.clip(lower=0)\nfinal_merge_f['diff_who_deaths'] = final_merge_f['WHO_deaths'].diff().fillna(0).astype(int)#.clip(lower=0)\n\n\n'''\nAllows keep negative values where they really can be. Insted of .clip()\n'''\nadditional_cols = ['growth_jhu_cases','diff_jhu_cases','growth_jhu_deaths',\n                   'diff_jhu_deaths','growth_who_cases','diff_who_cases',\n                   'growth_who_deaths','diff_who_deaths']\nmask = (final_merge_f['date'] == final_merge_f['date'].min())\nfinal_merge_f[additional_cols] = final_merge_f[additional_cols].where(~mask, other=0)","execution_count":72,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nDefining order of columns\n'''\n\nfinal_merge_f = final_merge_f[['date', 'Province/State', 'Country/Region',\n\n                 'jhu_cases', 'growth_jhu_cases', 'diff_jhu_cases', 'jhu_deaths', 'growth_jhu_deaths','diff_jhu_deaths',\n                 'WHO_cases', 'growth_who_cases', 'diff_who_cases', 'WHO_deaths', 'growth_who_deaths','diff_who_deaths',\n\n                 'Finance Country', 'cofinance_2017', 'cofinance_2018', 'cofinance_2019', 'continental_africa','country',\n                 'dov96', 'fragility_2017', 'fragility_2018', 'fragility_2019', 'francophone', 'gavi55', 'gavi68','gavi72',\n                 'gavi73', 'gavi77', 'gavi_region', 'gavi_region_sf', 'gavi_region_short', 'global', 'indo_pacific','iso3',\n                 'iso3_num', 'lang', 'pef_type', 'regional_je', 'regional_mena', 'regional_yfv', 'wb_long_2017','wb_long_2018',\n                 'wb_short_2017', 'wb_short_2018', 'who_region']]","execution_count":73,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nFinal request was to rename columns, to remove rows for the provinces/states, to remove column provinces/states and to make PEF Tier column integer\n'''\n\nfinal_merge_f_f = final_merge_f.rename(columns={'Country/region': 'Country',\n                     'jhu_cases': 'JHU Cases', 'growth_jhu_cases': 'JHU Cases Growth',\n                     'diff_jhu_cases': 'JHU Cases Difference',\n                     'jhu_deaths': 'JHU Deaths', 'growth_jhu_deaths': 'JHU Deaths Growth',\n                     'diff_jhu_deaths': 'JHU Deaths Difference',\n                     'WHO_cases': 'WHO Cases', 'growth_who_cases': 'WHO Cases Growth',\n                     'diff_who_cases': 'WHO Cases Difference',\n                     'WHO_deaths': 'WHO Deaths', 'growth_who_deaths': 'WHO Deaths Growth',\n                     'diff_who_deaths': 'WHO Deaths Difference',\n                     'cofinance_2019': 'Cofinance 2019', 'fragility_2017': '2017 Fragility Status',\n                     'fragility_2018': '2018 Fragility Status',\n                     'fragility_2019': '2019 Fragility Status', 'gavi_region': 'Gavi Region', 'pef_type': 'PEF Tier',\n                     'who_region': 'WHO Region'})\nfinal_merge_f_f = final_merge_f_f[~final_merge_f_f['Province/State'].notna()]  # removing rows where province/stare NOT nan\nfinal_merge_f_f = final_merge_f_f.drop(['Province/State', 'country', 'gavi_region_sf'], axis=1)\nfinal_merge_f_f['PEF Tier'] = final_merge_f_f['PEF Tier'].replace({\"Not PEF\": 0}).astype(int)","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nSaving output to desired format:\n'''\n# dates_ok = True #jhu_max_date == who_max_date\n\n# if not dates_ok:\n#     print('WHO and JHU data sets have different last dates.')\n#     print('WHO max date is {} , and JHU max date is {}'.format(who_max_date, jhu_max_date))\n#     print('Please insure that you are using the WHO dataset with {} as latest date'.format(jhu_max_date))\n# else:\nfinal_merge_f_f.to_excel('out_01.xlsx',index=False)\nfinal_merge_f_f.to_csv('out_01.csv',index=False)","execution_count":75,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pwd","execution_count":1,"outputs":[{"data":{"text/plain":"'/Users/dmitry/python_projects/pandas/WHO and GAVI/DEMO'"},"execution_count":1,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}